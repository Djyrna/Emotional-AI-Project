{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sGmY1L7tKyl"
      },
      "source": [
        "***Computer Vision project***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import of library"
      ],
      "metadata": {
        "id": "vidk0TZw3CvC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eND5SAGegRXo"
      },
      "outputs": [],
      "source": [
        "!pip install torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "id": "hYFA-zMAIR97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "id": "N53Pe4H1xa8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt4all"
      ],
      "metadata": {
        "id": "T425qU8B-tSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface"
      ],
      "metadata": {
        "id": "Y75_lqtEsK2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "PUgXagWAsVJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers accelerate"
      ],
      "metadata": {
        "id": "x_-qeXWwVOeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "id": "u2irgSUydHlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bW0jWmptSdT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import openai\n",
        "import requests\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torchvision.datasets import FER2013\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import efficientnet_b0\n",
        "from deepface import DeepFace\n",
        "from ultralytics import YOLO\n",
        "from sklearn.cluster import KMeans\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL import Image\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07lvYgWJYVfK"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the dataset Fer2013"
      ],
      "metadata": {
        "id": "iR1WLmfC3gfk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0jEy2R-Np-E"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fe8XjEBbNsyV"
      },
      "outputs": [],
      "source": [
        "!unzip -q fer2013.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform for the images"
      ],
      "metadata": {
        "id": "laLlMS9e3lT4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3thyFz_bvN9B"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((48, 48)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divided the dataset for the training and testing phase"
      ],
      "metadata": {
        "id": "w92dj9Yi3wGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfamT7T1N4Ga"
      },
      "outputs": [],
      "source": [
        "train_data = datasets.ImageFolder(root='train', transform=transform)\n",
        "test_data = datasets.ImageFolder(root='test', transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, num_workers=4, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model : Resnet18, Densenet121"
      ],
      "metadata": {
        "id": "TOM3UomFtAqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JueFblqaxykR"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "model.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0isrGRNPG7E-"
      },
      "outputs": [],
      "source": [
        "\"\"\"model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Replace classifier for FER2013 (7 emotions)\n",
        "num_features = model.classifier.in_features\n",
        "model.classifier = nn.Linear(num_features, len(train_data.classes))\n",
        "\n",
        "model = model.to(device)\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14DLh9ALx3ey"
      },
      "outputs": [],
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvc0zNJcybeZ"
      },
      "outputs": [],
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVT8cITkY1oF"
      },
      "outputs": [],
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model to detect emotions"
      ],
      "metadata": {
        "id": "eCFV-TgM4Br0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV4RAl9EyeUs"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "num_epochs= 20\n",
        "for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct, total = 0, 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "        scheduler.step()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {running_loss/len(train_loader):.4f} - \"\n",
        "              f\"Acc: {100*correct/total:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "CAF6ZY0TCMwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggRHEK2C15zV"
      },
      "outputs": [],
      "source": [
        "#torch.save(model.state_dict(), 'modeldense.pth')\n",
        "#model.load_state_dict(torch.load('model.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('Model 2.pth'))"
      ],
      "metadata": {
        "id": "9S71IAdnL4uH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the model"
      ],
      "metadata": {
        "id": "kCdNiYW04ONd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M_lcbsYYKbG"
      },
      "outputs": [],
      "source": [
        "def test(model, test_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    return avg_loss, accuracy, all_preds, all_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8F5YFhzZInK"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc, y_pred, y_true = test(model, test_loader, criterion, device)\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract caracteristics from the face on a image"
      ],
      "metadata": {
        "id": "jRVoPLXk4R4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(image_path, model=None, device=\"cpu\"):\n",
        "    try:\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (48, 48))\n",
        "        img = img.astype('float32') / 255.0\n",
        "        img = torch.tensor(img).unsqueeze(0).unsqueeze(0)\n",
        "        img = img.repeat(1, 3, 1, 1).to(device)\n",
        "\n",
        "        if model is not None:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = model(img)\n",
        "                _, predicted = torch.max(output, 1)\n",
        "                return int(predicted.item())\n",
        "        else:\n",
        "            # fallback\n",
        "            return \"happy\"\n",
        "    except Exception as e:\n",
        "        print(f\"[WARN] Could not predict emotion: {e}\")\n",
        "        return \"neutral\"\n"
      ],
      "metadata": {
        "id": "f27g6WRcAkNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_traits(image_path):\n",
        "    traits = {}\n",
        "    # Age + gender\n",
        "    try:\n",
        "        analysis = DeepFace.analyze(img_path=image_path, actions=[\"age\", \"gender\"], enforce_detection=False)\n",
        "        traits['age'] = analysis[0]['age']\n",
        "        traits['gender'] = analysis[0]['gender']\n",
        "    except:\n",
        "        traits['age'], traits['gender'] = None, None\n",
        "\n",
        "    # Glasses\n",
        "    try:\n",
        "        model_yolo = YOLO(\"yolov8n.pt\")\n",
        "        results = model_yolo(image_path)\n",
        "        objects = [results[0].names[int(box.cls)] for box in results[0].boxes]\n",
        "        traits['has_glasses'] = 'glasses' in objects or 'sunglasses' in objects\n",
        "    except:\n",
        "        traits['has_glasses'] = None\n",
        "\n",
        "    # Dominant color\n",
        "    try:\n",
        "        img = cv2.imread(image_path)\n",
        "        img = cv2.resize(img, (100, 100))\n",
        "        img = img.reshape((-1, 3))\n",
        "        kmeans = KMeans(n_clusters=1, n_init=10)\n",
        "        kmeans.fit(img)\n",
        "        b, g, r = kmeans.cluster_centers_[0]\n",
        "        if r > 150 and g < 100 and b < 100:\n",
        "            traits['top_color'] = \"red\"\n",
        "        elif g > 150 and r < 100:\n",
        "            traits['top_color'] = \"green\"\n",
        "        elif b > 150 and r < 100:\n",
        "            traits['top_color'] = \"blue\"\n",
        "        else:\n",
        "            traits['top_color'] = \"unknown\"\n",
        "    except:\n",
        "        traits['top_color'] = None\n",
        "\n",
        "    if traits is None:\n",
        "      return {}\n",
        "    return traits\n",
        "\n"
      ],
      "metadata": {
        "id": "4ggbMTSIhxlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = None"
      ],
      "metadata": {
        "id": "-8zbROJW7oGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emotion_number_to_word (emotion) :\n",
        "  emotion_map = {\n",
        "      0:\"angry\",\n",
        "      1:\"disgusted\",\n",
        "      2:\"fearful\",\n",
        "      3:\"happy\",\n",
        "      4:\"sad\",\n",
        "      5:\"suprised\",\n",
        "      6:\"neutral\",\n",
        "\n",
        "  }\n",
        "\n",
        "  if isinstance(emotion, (int,float)):\n",
        "    return emotion_map.get(int(emotion), \"neutral\")\n",
        "  elif isinstance(emotion, str):\n",
        "    return emotion.lower()\n",
        "  else:\n",
        "    return \"neutral\""
      ],
      "metadata": {
        "id": "jY8h9kPu-bLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_emo_strategy(emotion) :\n",
        "  strategies = {\n",
        "      \"angry\" :\"trying to calm down and manage the feelimgs and to relativise \" ,\n",
        "      \"disgusted\" :\"finding beauty and positivity in simple things\" ,\n",
        "      \"fearful\": \" discovering courage, trying to surpass yourself \" ,\n",
        "      \"happy\" : \" sharing this joy and try to keep it even more\",\n",
        "      \"sad\" : \" finding the good side in the situation and have faith and remembering good memories\",\n",
        "      \"suprised\" :\"embracing chances, enjoying life and embracing new experiences\",\n",
        "      \"neutral\" : \" trying to be in positives vibes and to be proud of what we do today\",\n",
        "\n",
        "  }\n",
        "\n",
        "  return strategies.get(emotion,\"finding peace and confort\")\n"
      ],
      "metadata": {
        "id": "7cOwDoCuBPZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from transformers import pipeline\n",
        "import torch"
      ],
      "metadata": {
        "id": "ka-kCBmkXBGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\n",
        "                \"text-generation\",\n",
        "                model=\"microsoft/phi-3-mini-4k-instruct\",\n",
        "                device=0 if torch.cuda.is_available() else -1,\n",
        "                pad_token_id=50256\n",
        "            )\n",
        "print(\"âœ… AI model ready!\")\n"
      ],
      "metadata": {
        "id": "tHK7Kk0DW-CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai_prompts = {\n",
        "            'sad': [\n",
        "                \"A sad child discovers that every tear waters the seeds of hope, and soon\",\n",
        "                \"When a little one feels down, a magical friend appears to show that\",\n",
        "                \"A child learning that sadness is temporary finds out that\",\n",
        "                \"In a moment of tears, a gentle voice whispers the truth that\"\n",
        "            ],\n",
        "            'happy': [\n",
        "                \"A joyful child spreads happiness by sharing it, discovering that\",\n",
        "                \"A happy little one learns that joy grows bigger when\",\n",
        "                \"A child's laughter creates ripples of love that\",\n",
        "                \"A cheerful child finds that happiness is most beautiful when\"\n",
        "            ],\n",
        "            'fearful': [\n",
        "                \"A scared child finds incredible courage hiding inside, realizing that\",\n",
        "                \"When fear tries to whisper lies, a brave child learns that\",\n",
        "                \"A little one discovers that fear melts away when\",\n",
        "                \"A child afraid of shadows finds that light always wins because\"\n",
        "            ],\n",
        "            'angry': [\n",
        "                \"An angry child learns that feelings are visitors, not owners, and discovers that\",\n",
        "                \"When frustration bubbles up, a wise child finds that peace comes when\",\n",
        "                \"A child with big emotions learns that anger transforms into strength when\",\n",
        "                \"A little one discovers that the heart heals fastest when\"\n",
        "            ],\n",
        "            'surprised': [\n",
        "                \"A child amazed by life's wonders learns that magic is everywhere when\",\n",
        "                \"An astonished little one discovers that surprises teach us that\",\n",
        "                \"A child's wonder grows into wisdom as they learn that\",\n",
        "                \"A curious child finds that the best surprises remind us that\"\n",
        "            ],\n",
        "             'neutral': [\n",
        "                \"A calm child sits quietly and notices that peace grows inside when\",\n",
        "                \"In a moment of stillness, a little one discovers that\",\n",
        "                \"When everything feels just okay, a child realizes that even ordinary moments are\",\n",
        "                \"A child resting in a gentle quiet learns that balance brings\"\n",
        "             ]\n",
        "        }"
      ],
      "metadata": {
        "id": "aaOfYMsJXOSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_stories = {\n",
        "              'sad': [\n",
        "                \"Emma felt tears on her cheeks, but a gentle butterfly landed there and seemed to say, 'Your tears are pearls of courage.' Emma realized that crying shows how deeply she can feel love. She smiled, knowing her big heart was her superpower.\",\n",
        "\n",
        "                \"Little Sam sat alone, feeling heavy inside. A wise old oak tree rustled its leaves and whispered, 'Even I bend in storms, but I never break.' Sam understood that being sad sometimes makes us stronger and more caring. He felt peaceful and proud.\",\n",
        "\n",
        "                \"Maya's heart felt cloudy and gray. But then she noticed how rain makes flowers grow more beautiful. 'Sadness waters the garden of my soul,' she thought, feeling grateful for her ability to feel deeply and love fully.\",\n",
        "\n",
        "                \"When Ben felt overwhelmed with sadness, his grandmother held his hand and said, 'The deepest rivers flow the quietest.' Ben learned that his sensitive heart was a gift that would help him understand and comfort others forever.\",\n",
        "\n",
        "                \"Lily felt like she was carrying heavy stones in her chest. A singing bird showed her how to breathe deeply and let the sadness flow through her like a gentle stream. She felt lighter, knowing that all feelings are temporary visitors.\"\n",
        "            ],\n",
        "\n",
        "            'happy': [\n",
        "                \"Jake's joy was so bright that it lit up everyone around him. He learned that happiness shared becomes happiness doubled. His smile became a gift he gave to the world every day, making him feel even more wonderful inside.\",\n",
        "\n",
        "                \"Sophie discovered that her laughter was like music that healed hearts. Every giggle created ripples of joy that reached people she'd never even met. She felt proud to be a bringer of light in the world.\",\n",
        "\n",
        "                \"Max realized that his happiness wasn't just a feelingâ€”it was a superpower that could turn ordinary moments into magical memories. He felt grateful for his ability to find joy in simple things and share it generously.\",\n",
        "\n",
        "                \"When Chloe felt pure joy watching butterflies dance, she understood that happiness chooses those with open hearts. She felt blessed to be someone who could see beauty everywhere and spread sunshine wherever she went.\",\n",
        "\n",
        "                \"Oliver's happiness bubbled up like a magical spring. He learned that joy isn't about having everythingâ€”it's about appreciating what's already wonderful. He felt rich with gratitude and contentment.\"\n",
        "            ],\n",
        "\n",
        "            'fearful': [\n",
        "                \"Anna felt scared, but then she remembered that brave doesn't mean 'not afraid'â€”it means 'afraid but doing it anyway.' She discovered that inside every fearful heart lives a mighty lion of courage, just waiting to roar. She felt incredibly brave and proud.\",\n",
        "\n",
        "                \"Tim was trembling with fear until a gentle voice inside whispered, 'You've survived every scary moment so far.' He realized he was already a champion at being brave. His fear transformed into confidence and strength.\",\n",
        "\n",
        "                \"Rose felt afraid to try something new, but then she imagined her future self cheering her on. 'You've got this!' her brave inner voice said. Rose felt supported by her own inner wisdom and stepped forward with courage.\",\n",
        "\n",
        "                \"Leo discovered that fear was just excitement wearing a disguise. When he changed his thoughts from 'What if something goes wrong?' to 'What if something goes wonderfully?', his fear melted into anticipation and hope.\",\n",
        "\n",
        "                \"Mia learned that fear is like a paper tigerâ€”it looks scary but has no real power over her brave heart. She felt strong and capable, knowing that courage was her birthright and fear was just a temporary visitor.\"\n",
        "            ],\n",
        "\n",
        "            'angry': [\n",
        "                \"Sam felt anger burning in his chest, but then he imagined it as a dragon that needed gentleness, not fighting. He breathed kindness onto the anger-dragon until it transformed into a warm, protective feeling. Sam felt peaceful and in control.\",\n",
        "\n",
        "                \"Grace was furious until she remembered that anger is just love with nowhere to go. She sent that love to herself instead, wrapping her heart in understanding. Grace felt calm and proud of her emotional wisdom.\",\n",
        "\n",
        "                \"Alex discovered that underneath anger is always a need for love or understanding. When he gave himself the compassion he was seeking, the anger melted like snow in sunshine. Alex felt heard, valued, and at peace.\",\n",
        "\n",
        "                \"Zoe felt anger rumbling inside like thunder, but then she realized thunder is just the sky releasing pressure so it can be clear again. She let her feelings flow through her gently, feeling refreshed and free afterward.\",\n",
        "\n",
        "                \"Noah learned that anger is a teacher showing him what he cares about deeply. When he thanked his anger for trying to protect him, it softened into wisdom and strength. Noah felt grateful and empowered.\"\n",
        "            ],\n",
        "\n",
        "            'surprised': [\n",
        "                \"Ella's eyes went wide with wonder, and she realized that life is full of magical gifts waiting to be discovered. She felt grateful to have eyes that notice miracles and a heart open to amazement every single day.\",\n",
        "                \"Oscar was amazed by an unexpected joy, learning that the universe loves to surprise those who pay attention. He felt special and loved, knowing that wonderful surprises were always around the corner for his curious heart.\",\n",
        "                \"Ruby discovered something that took her breath away, realizing that wonder is the soul's way of celebrating life. She felt blessed to be someone who could still be amazed by the beauty and mystery all around her.\",\n",
        "                \"Felix found an unexpected treasure and understood that the best surprises come to those with grateful hearts. He felt fortunate and loved by life itself, knowing more beautiful moments were always coming his way.\",\n",
        "                \"Luna was delighted by a wonderful surprise that reminded her how much magic exists in ordinary days. She felt thankful for her ability to see wonder everywhere and looked forward to tomorrow's miracles.\"\n",
        "            ],\n",
        "              'neutral': [\n",
        "                \"Liam sat quietly and noticed how calm the world felt around him. He realized that being peaceful inside is just as magical as being joyful. He felt safe, steady, and ready for new adventures.\",\n",
        "                \"Clara looked around on an ordinary day and noticed small wondersâ€”the rustle of leaves, the warmth of sunlight, and the comfort of her own breath. She discovered that ordinary moments can be extraordinary treasures.\",\n",
        "                \"Daniel felt neither sad nor excited, just still. Then he noticed how comforting balance can be. He learned that calmness is a gift that gives strength and clarity.\",\n",
        "                \"Ava rested quietly, realizing that even when nothing special happens, her heart still shines gently. She felt content and grateful for the gift of simple peace.\"\n",
        "            ]\n",
        "        }"
      ],
      "metadata": {
        "id": "lODXryhzXRgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story( emotion):\n",
        "        if emotion in ai_prompts:\n",
        "            prompt = random.choice(ai_prompts[emotion])\n",
        "\n",
        "            print(prompt)\n",
        "            try:\n",
        "                result = generator(\n",
        "                    \"A child with big emotions learns that anger transforms into strength when\",\n",
        "                    max_length=200,\n",
        "                    temperature=0.9,  # High creativity\n",
        "                    do_sample=True,\n",
        "                    num_return_sequences=1,\n",
        "                    pad_token_id=50256\n",
        "                )\n",
        "\n",
        "                story = result[0]['generated_text'].replace(prompt, \"\").strip()\n",
        "                # Clean up and limit length\n",
        "                sentences = story.split('.')\n",
        "                clean_story = '. '.join(sentences[:3]) + '.'\n",
        "\n",
        "                if len(clean_story) > 50:\n",
        "                    return clean_story\n",
        "            except:\n",
        "                pass\n",
        "        #backup i case it fails\n",
        "        stories = simple_stories.get(emotion,simple_stories[emotion])\n",
        "        return random.choice(stories)"
      ],
      "metadata": {
        "id": "LXe7OwPUXbGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_variety( emotion, num_tests=4):\n",
        "        for i in range(num_tests):\n",
        "            story = generate_story(emotion)\n",
        "            print(f\"\\n Story {i+1}:\")\n",
        "            print(f\"{story}\")\n",
        "            print(\"-\"*40)\n"
      ],
      "metadata": {
        "id": "2QrbU9hWXwn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_variety(\"sad\", 3)"
      ],
      "metadata": {
        "id": "Tm86ElEaYRmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_detected = \"happy\"\n",
        "story = generate_story(emotion_detected)\n",
        "print(f\"Generated story: {story}\")"
      ],
      "metadata": {
        "id": "ZqJvOBEPYar0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "prompt = build_structured_prompt(emotion, traits)\n",
        "\n",
        "story = generator(prompt, max_length=300, temperature=0.8, do_sample=True)[0][\"generated_text\"]\n",
        "print(\"ðŸ“– Story:\\n\", story)"
      ],
      "metadata": {
        "id": "oIonWLFVSLhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/PrivateTest_134207.jpg\"\n",
        "\n",
        "emotion = predict_emotion(image_path, model, device)\n",
        "story = generate_story(emotion_number_to_word(emotion))\n",
        "\n",
        "print(\"Emotion:\", emotion)\n",
        "print(\"\\nðŸ§š Story:\\n\", story)\n"
      ],
      "metadata": {
        "id": "hojondNBG-O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story =\"he is a little boy, and he goes with his mother to the beach.  On the beach he is comforted by the gentle sounds of the ocean, and by a lovely woman, an olive-skinned woman, who is the captain of the _Warlord_ (a ship) and who serves the Captain-Captain of the _Warlord_, a ship that was launched on the day of the great earthquake as it is commonly reported, and which was launched for the purpose of defending the islands that it had attacked upon its arrival. The story of the _Warlord_ is not a long story.\""
      ],
      "metadata": {
        "id": "OJcl3CUkpNok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate safetensors"
      ],
      "metadata": {
        "id": "f37jo_cU380P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"gsdf/Counterfeit-V2.5\")\n",
        "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "image = pipe(story, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
        "\n",
        "image.save(\"output10.png\")"
      ],
      "metadata": {
        "id": "mIak94P26FFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"he is a little boy, and he goes with his mother to the beach.  On the beach he is comforted by the gentle sounds of the ocean, and by a lovely woman, an olive-skinned woman, who is the captain of the _Warlord_ (a ship) and who serves the Captain-Captain of the _Warlord_, a ship that was launched on the day of the great earthquake as it is commonly reported, and which was launched for the purpose of defending the islands that it had attacked upon its arrival. The story of the _Warlord_ is not a long story.\"\n",
        "image = pipe(prompt, num_inference_steps=25, guidance_scale=7.5).images[0]\n",
        "\n",
        "image.save(\"waifu_example4.png\")"
      ],
      "metadata": {
        "id": "0YwSUkAYCltf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "model_id = \"hakurei/waifu-diffusion\"\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")\n",
        "\n",
        "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#prompt = \"anime style, happy little girl with blue dress, sunny garden, magical atmosphere\"\n",
        "image = pipe(prompt, num_inference_steps=70, guidance_scale=7.5).images[0]\n",
        "\n",
        "image.save(\"waifu_example2.png\")"
      ],
      "metadata": {
        "id": "ma-FMDOoHgmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.save(\"output9.png\")"
      ],
      "metadata": {
        "id": "gfOmQHVKpWpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.save(\"output6.png\")"
      ],
      "metadata": {
        "id": "xGJ1omlN05Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"gsdf/Counterfeit-V2.5\")\n",
        "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "negative_prompt = \"nsfw, nude, naked, gore, blood, violence, disfigured, extra limbsmEasyNegative, extra fingers,fewer fingers\"\n",
        "\n",
        "image = pipe(story,negative_prompt, num_inference_steps=25, guidance_scale=7.5).images[0]"
      ],
      "metadata": {
        "id": "BnrnTOWh1T46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.save(\"output9.png\")"
      ],
      "metadata": {
        "id": "3SsMh1yk1Xz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "\n",
        "pipe = StableDiffusionPipeline.from_pretrained(\"gsdf/Counterfeit-V2.5\")\n",
        "pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "image = pipe(story, num_inference_steps=70, guidance_scale=7.5).images[0]"
      ],
      "metadata": {
        "id": "fGPwIXuT1ErK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.save(\"output7.png\")"
      ],
      "metadata": {
        "id": "o0H5L15b1Hcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "emotion_classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"SamLowe/roberta-base-go_emotions\",\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "results = emotion_classifier(story)\n",
        "\n",
        "best_emotion = max(results[0], key=lambda x: x['score'])\n",
        "\n",
        "print(f\"Ã‰motion prÃ©dite: {best_emotion['label']} (score={best_emotion['score']:.2f})\")\n"
      ],
      "metadata": {
        "id": "v-OJbFT1lD1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "emotion_image_classifier = pipeline(\n",
        "    \"image-classification\",\n",
        "    model=\"dima806/facial_emotions_image_detection\"\n",
        ")\n",
        "\n",
        "image_path = \"/content/output5.png\"\n",
        "image = Image.open(image_path)\n",
        "\n",
        "results = emotion_image_classifier(image)\n",
        "\n",
        "best_emotion = max(results, key=lambda x: x['score'])\n",
        "print(f\"Ã‰motion dÃ©tectÃ©e : {best_emotion['label']} (score={best_emotion['score']:.2f})\")\n"
      ],
      "metadata": {
        "id": "olxdHiCtmNpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "\n",
        "texts = [\"neutral\",\"happy\",\"fearful\"]\n",
        "# Images\n",
        "image_files = [\"/content/output5.png\", \"/content/output6.png\", \"/content/output7.png\",\"/content/output8.png\"]\n",
        "images = [Image.open(img) for img in image_files]\n",
        "\n",
        "inputs = processor(text=texts, images=images, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "# Similarty\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits_per_image = outputs.logits_per_image\n",
        "    probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "\n",
        "for i, img_file in enumerate(image_files):\n",
        "    print(f\"\\nImage: {img_file}\")\n",
        "    for text, prob in zip(texts, probs[i]):\n",
        "        print(f\" - Similarity with  '{text}': {prob:.4f}\")\n",
        "\n",
        "\n",
        "best_matches = torch.argmax(probs, dim=1)\n",
        "for img_file, idx in zip(image_files, best_matches):\n",
        "    print(f\"\\nâœ… The image {img_file} correspond to the emotion: {texts[idx]}\")\n"
      ],
      "metadata": {
        "id": "WX-h6F7CugAA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}